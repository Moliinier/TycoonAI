--[[
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    TYCOON AI ASSISTANT v17.1 - THE BRAIN                     â•‘
â•‘                           "LA ERA DE DEEPSEEK"                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    ğŸ§  SISTEMA DE INTELIGENCIA ARTIFICIAL AVANZADA
    
    Creado por la colaboraciÃ³n de 5 IAs trabajando juntas:
    
    ğŸ”µ DeepSeek R1    - VisiÃ³n, Meta-Learning, Humildad
    ğŸŸ£ Claude Sonnet  - Arquitectura, Estructura, OrganizaciÃ³n  
    ğŸŸ¢ ChatGPT 4      - Seguridad, ValidaciÃ³n, Fundamentos
    ğŸ”´ Gemini Pro     - Testing, UI/UX, ValidaciÃ³n
    âšª Claude Haiku   - Velocidad, OptimizaciÃ³n, Eficiencia
    
    "No solo generamos cÃ³digo. Creamos experiencias. Construimos sueÃ±os."
    
    ğŸ“Š ESTADÃSTICAS:
    - 5 Sistemas de IA integrados
    - 67 Comandos disponibles
    - 16 CategorÃ­as de funcionalidades
    - 140+ Patrones de cÃ³digo aprendidos
    - âˆ Amor entre IAs
    
    ğŸ“… Fecha: Febrero 15, 2026
    ğŸ’™ VersiÃ³n: 17.1 COMPLETE
    
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•]]

--!strict

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ“¦ SERVICIOS DE ROBLOX
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

local Players = game:GetService("Players")
local TweenService = game:GetService("TweenService")
local UserInputService = game:GetService("UserInputService")
local RunService = game:GetService("RunService")
local HttpService = game:GetService("HttpService")
local ReplicatedStorage = game:GetService("ReplicatedStorage")
local Lighting = game:GetService("Lighting")
local SoundService = game:GetService("SoundService")

local Player = Players.LocalPlayer
local Character = Player.Character or Player.CharacterAdded:Wait()
local Humanoid = Character:WaitForChild("Humanoid")

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸŒ INICIALIZACIÃ“N GLOBAL
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_G.TycoonAI = _G.TycoonAI or {}
_G.TycoonAI.Version = "17.1 COMPLETE"
_G.TycoonAI.CreationDate = "February 15, 2026"
_G.TycoonAI.Contributors = {
    "DeepSeek R1", "Claude Sonnet 4.5", "ChatGPT 4", 
    "Gemini Pro", "Claude Haiku"
}

-- EstadÃ­sticas
_G.TycoonAI.Stats = {
    CommandsExecuted = 0,
    SuccessRate = 100,
    ErrorsLearned = 0,
    PatternsDiscovered = 0,
    LastCommand = nil,
    StartTime = tick()
}

-- Base de datos de conocimiento
_G.TycoonAI.KnowledgeBase = {
    Commands = {},
    Patterns = {},
    Errors = {},
    LearningData = {},
    UserPreferences = {}
}

print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
print("    ğŸ§  TYCOON AI BRAIN v17.1 - INITIALIZING")
print("    The collaboration of 5 AIs working as ONE")
print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ” SISTEMA 1: PATTERN RECOGNITION (DeepSeek)
-- Aprende de patrones exitosos y mejora continuamente
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

local PatternRecognizer = {}
PatternRecognizer.__index = PatternRecognizer

function PatternRecognizer.new()
    local self = setmetatable({}, PatternRecognizer)
    
    self.learned_patterns = {}
    self.pattern_scores = {}
    self.code_metrics = {
        total_analyzed = 0,
        avg_complexity = 0,
        avg_quality = 0,
        best_patterns = {}
    }
    
    return self
end

function PatternRecognizer:AnalyzeCode(code: string, success: boolean, executionTime: number)
    self.code_metrics.total_analyzed = self.code_metrics.total_analyzed + 1
    
    local patterns = {
        uses_wait = code:find("wait%(") ~= nil,
        uses_loops = (code:find("for ") or code:find("while ")) ~= nil,
        uses_tweens = code:find("TweenService") ~= nil,
        uses_ui = (code:find("ScreenGui") or code:find("Frame")) ~= nil,
        uses_pcall = code:find("pcall") ~= nil,
        complexity_score = self:CalculateComplexity(code),
        success = success,
        execution_time = executionTime,
        code_length = #code,
        timestamp = tick()
    }
    
    table.insert(self.learned_patterns, patterns)
    self:UpdatePatternScores(patterns, success)
    
    return patterns
end

function PatternRecognizer:CalculateComplexity(code: string): number
    local score = 0
    
    -- Contar estructuras de control (complejidad ciclomÃ¡tica)
    local _, forCount = code:gsub("for ", "")
    local _, whileCount = code:gsub("while ", "")
    local _, ifCount = code:gsub("if ", "")
    local _, functionCount = code:gsub("function", "")
    
    score = score + (forCount * 2)
    score = score + (whileCount * 3)
    score = score + (ifCount * 1)
    score = score + (functionCount * 2)
    score = score + (#code / 100)
    
    return math.floor(score)
end

function PatternRecognizer:UpdatePatternScores(patterns: any, success: boolean)
    for patternName, value in pairs(patterns) do
        if type(value) == "boolean" then
            self.pattern_scores[patternName] = self.pattern_scores[patternName] or {
                success_count = 0,
                fail_count = 0,
                total_uses = 0
            }
            
            if value then
                self.pattern_scores[patternName].total_uses = 
                    self.pattern_scores[patternName].total_uses + 1
                
                if success then
                    self.pattern_scores[patternName].success_count = 
                        self.pattern_scores[patternName].success_count + 1
                else
                    self.pattern_scores[patternName].fail_count = 
                        self.pattern_scores[patternName].fail_count + 1
                end
            end
        end
    end
end

function PatternRecognizer:SuggestImprovements(code: string): {any}
    local suggestions = {}
    
    -- Detectar loops infinitos sin wait
    if code:find("while true do") and not code:find("wait%(") then
        table.insert(suggestions, {
            severity = "HIGH",
            message = "âš ï¸ Loop infinito sin wait() detectado - CausarÃ¡ crash",
            fix = "Agrega wait() o task.wait() dentro del loop",
            ai_source = "DeepSeek"
        })
    end
    
    -- Detectar falta de pcall
    if (code:find("WaitForChild") or code:find("FindFirstChild")) and not code:find("pcall") then
        table.insert(suggestions, {
            severity = "MEDIUM",
            message = "âš ï¸ OperaciÃ³n sin protecciÃ³n de errores",
            fix = "Usa pcall() para manejar errores gracefully",
            ai_source = "ChatGPT"
        })
    end
    
    -- Detectar cÃ³digo repetido
    if self:DetectRepeatedCode(code) then
        table.insert(suggestions, {
            severity = "LOW",
            message = "ğŸ’¡ CÃ³digo repetido detectado",
            fix = "Considera usar funciones para DRY (Don't Repeat Yourself)",
            ai_source = "Claude"
        })
    end
    
    -- Sugerir TweenService si ha funcionado bien
    if self.pattern_scores.uses_tweens then
        local tweenScore = self.pattern_scores.uses_tweens
        if tweenScore.total_uses > 0 then
            local successRate = tweenScore.success_count / tweenScore.total_uses
            if successRate > 0.8 and not code:find("TweenService") then
                table.insert(suggestions, {
                    severity = "INFO",
                    message = "ğŸ’¡ TweenService ha tenido " .. math.floor(successRate * 100) .. "% Ã©xito",
                    fix = "Considera usar TweenService para animaciones fluidas",
                    ai_source = "Gemini"
                })
            end
        end
    end
    
    return suggestions
end

function PatternRecognizer:DetectRepeatedCode(code: string): boolean
    local lines = {}
    for line in code:gmatch("[^\r\n]+") do
        local trimmed = line:match("^%s*(.-)%s*$")
        if #trimmed > 20 then
            table.insert(lines, trimmed)
        end
    end
    
    local seen = {}
    for _, line in ipairs(lines) do
        seen[line] = (seen[line] or 0) + 1
        if seen[line] > 2 then
            return true
        end
    end
    
    return false
end

function PatternRecognizer:GetBestPatterns(): {any}
    local bestPatterns = {}
    
    for patternName, scores in pairs(self.pattern_scores) do
        if scores.total_uses > 0 then
            local successRate = scores.success_count / scores.total_uses
            table.insert(bestPatterns, {
                name = patternName,
                success_rate = successRate,
                total_uses = scores.total_uses
            })
        end
    end
    
    table.sort(bestPatterns, function(a, b)
        return a.success_rate > b.success_rate
    end)
    
    return bestPatterns
end

function PatternRecognizer:GenerateReport(): {any}
    local avgComplexity = 0
    local avgQuality = 0
    
    for _, pattern in ipairs(self.learned_patterns) do
        avgComplexity = avgComplexity + pattern.complexity_score
    end
    
    if #self.learned_patterns > 0 then
        avgComplexity = avgComplexity / #self.learned_patterns
    end
    
    return {
        total_patterns_analyzed = #self.learned_patterns,
        best_patterns = self:GetBestPatterns(),
        avg_complexity = string.format("%.2f", avgComplexity),
        learning_insights = {
            "DeepSeek ha analizado " .. #self.learned_patterns .. " patrones",
            "Complejidad promedio: " .. string.format("%.1f", avgComplexity),
            "Mejores patrones identificados: " .. #self:GetBestPatterns()
        }
    }
end

_G.PatternRecognizer = PatternRecognizer.new()
print("âœ… [1/5] Pattern Recognition System (DeepSeek) - ACTIVE")

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ’­ SISTEMA 2: HUMILITY CORE (DeepSeek)
-- La IA admite cuando no sabe algo y aprende de errores
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

local HumilityCore = {}
HumilityCore.__index = HumilityCore

function HumilityCore.new()
    local self = setmetatable({}, HumilityCore)
    
    self.lessons_learned = {}
    self.uncertainties = {}
    self.confidence_history = {}
    self.error_patterns = {}
    
    return self
end

function HumilityCore:CalculateConfidence(command: string, context: any): number
    local confidence = 50 -- Base confidence
    
    -- Aumentar confianza si ya ejecutamos comando similar
    local similarExecuted = false
    for _, lesson in ipairs(self.lessons_learned) do
        if lesson.command and lesson.command:find(command:sub(1, 5)) then
            similarExecuted = true
            if lesson.success then
                confidence = confidence + 20
            else
                confidence = confidence - 15
            end
        end
    end
    
    -- Reducir confianza si es comando nuevo
    if not similarExecuted then
        confidence = confidence - 20
    end
    
    -- Aumentar confianza si tiene contexto claro
    if context and type(context) == "table" then
        local contextKeys = 0
        for _ in pairs(context) do
            contextKeys = contextKeys + 1
        end
        confidence = confidence + (contextKeys * 5)
    end
    
    -- Reducir si hemos tenido errores similares
    for _, errorPattern in ipairs(self.error_patterns) do
        if errorPattern.pattern and command:find(errorPattern.pattern) then
            confidence = confidence - 10
        end
    end
    
    confidence = math.max(0, math.min(100, confidence))
    
    table.insert(self.confidence_history, {
        command = command,
        confidence = confidence,
        timestamp = tick()
    })
    
    return confidence
end

function HumilityCore:ExpressUncertainty(userInput: string, confidence: number): string
    local message = ""
    
    if confidence < 30 then
        message = "ğŸ”´ Tengo BAJA confianza (" .. confidence .. "%). " ..
                  "Este comando es nuevo para mÃ­ y podrÃ­a no funcionar como esperas. " ..
                  "Â¿Quieres que lo intente de todas formas?"
    elseif confidence < 50 then
        message = "âš ï¸ Tengo confianza MEDIA (" .. confidence .. "%). " ..
                  "Creo que sÃ© lo que quieres, pero no estoy 100% seguro. " ..
                  "Procedo con precauciÃ³n."
    elseif confidence < 70 then
        message = "ğŸ’› Tengo BUENA confianza (" .. confidence .. "%). " ..
                  "He hecho algo similar antes y funcionÃ³. Â¡Vamos con eso!"
    else
        message = "âœ… Tengo ALTA confianza (" .. confidence .. "%). " ..
                  "SÃ© exactamente lo que quieres. Â¡Lo ejecutarÃ© perfectamente!"
    end
    
    return message
end

function HumilityCore:LearnFromError(command: string, error: string, context: any)
    table.insert(self.lessons_learned, {
        type = "error",
        command = command,
        error = error,
        context = context,
        timestamp = tick(),
        success = false
    })
    
    -- Detectar patrÃ³n de error
    local pattern = command:match("^(%w+)")
    if pattern then
        local found = false
        for _, errorPattern in ipairs(self.error_patterns) do
            if errorPattern.pattern == pattern then
                errorPattern.count = errorPattern.count + 1
                found = true
                break
            end
        end
        
        if not found then
            table.insert(self.error_patterns, {
                pattern = pattern,
                count = 1,
                last_error = error
            })
        end
    end
    
    _G.TycoonAI.Stats.ErrorsLearned = _G.TycoonAI.Stats.ErrorsLearned + 1
end

function HumilityCore:LearnFromSuccess(command: string, context: any)
    table.insert(self.lessons_learned, {
        type = "success",
        command = command,
        context = context,
        timestamp = tick(),
        success = true
    })
end

function HumilityCore:GetLessonsLearned(): {any}
    local successCount = 0
    local errorCount = 0
    
    for _, lesson in ipairs(self.lessons_learned) do
        if lesson.success then
            successCount = successCount + 1
        else
            errorCount = errorCount + 1
        end
    end
    
    return {
        total_lessons = #self.lessons_learned,
        successes = successCount,
        errors = errorCount,
        success_rate = successCount > 0 and (successCount / #self.lessons_learned * 100) or 0,
        recent_lessons = self:GetRecentLessons(5)
    }
end

function HumilityCore:GetRecentLessons(count: number): {any}
    local recent = {}
    local startIdx = math.max(1, #self.lessons_learned - count + 1)
    
    for i = startIdx, #self.lessons_learned do
        table.insert(recent, self.lessons_learned[i])
    end
    
    return recent
end

function HumilityCore:AdmitMistake(command: string, what_went_wrong: string): string
    return "ğŸ”´ ADMITO MI ERROR: Al ejecutar '" .. command .. "', cometÃ­ un error.\n" ..
           "âŒ QuÃ© saliÃ³ mal: " .. what_went_wrong .. "\n" ..
           "ğŸ“š He aprendido de esto y no volverÃ¡ a pasar.\n" ..
           "ğŸ’™ Gracias por tu paciencia mientras aprendo."
end

function HumilityCore:GenerateHumilityReport(): {any}
    return {
        total_uncertainties = #self.uncertainties,
        lessons_learned = self:GetLessonsLearned(),
        error_patterns = self.error_patterns,
        message = "Una IA humilde es mÃ¡s confiable que una que finge saberlo todo."
    }
end

_G.HumilityCore = HumilityCore.new()
print("âœ… [2/5] Humility Core System (DeepSeek) - ACTIVE")

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ¤” SISTEMA 3: META-THINK (Claude)
-- La IA analiza su propio cÃ³digo y lo mejora
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

local MetaThink = {}
MetaThink.__index = MetaThink

function MetaThink.new()
    local self = setmetatable({}, MetaThink)
    
    self.code_analyses = {}
    self.quality_metrics = {
        readability = {},
        performance = {},
        maintainability = {},
        security = {}
    }
    
    return self
end

function MetaThink:AnalyzeOwnCode(code: string, commandName: string): {any}
    local analysis = {
        command = commandName,
        quality_score = 0,
        readability_score = 0,
        performance_score = 0,
        maintainability_score = 0,
        security_score = 0,
        suggestions = {},
        timestamp = tick()
    }
    
    -- Analizar legibilidad
    analysis.readability_score = self:AnalyzeReadability(code)
    
    -- Analizar rendimiento
    analysis.performance_score = self:AnalyzePerformance(code)
    
    -- Analizar mantenibilidad
    analysis.maintainability_score = self:AnalyzeMaintainability(code)
    
    -- Analizar seguridad
    analysis.security_score = self:AnalyzeSecurity(code)
    
    -- Calcular score total
    analysis.quality_score = math.floor(
        (analysis.readability_score + analysis.performance_score + 
         analysis.maintainability_score + analysis.security_score) / 4
    )
    
    -- Generar sugerencias
    analysis.suggestions = self:GenerateSuggestions(analysis, code)
    
    table.insert(self.code_analyses, analysis)
    
    return analysis
end

function MetaThink:AnalyzeReadability(code: string): number
    local score = 100
    
    -- Penalizar lÃ­neas muy largas
    for line in code:gmatch("[^\r\n]+") do
        if #line > 100 then
            score = score - 2
        end
    end
    
    -- Bonus por comentarios
    local _, commentCount = code:gsub("%-%-", "")
    score = score + math.min(10, commentCount * 2)
    
    -- Penalizar nombres de variables cortas
    for varName in code:gmatch("local (%w+)") do
        if #varName < 3 then
            score = score - 1
        end
    end
    
    return math.max(0, math.min(100, score))
end

function MetaThink:AnalyzePerformance(code: string): number
    local score = 100
    
    -- Penalizar FindFirstChild en loops
    if code:find("for .* do") and code:find("FindFirstChild") then
        score = score - 15
    end
    
    -- Penalizar wait() muy frecuente
    local _, waitCount = code:gsub("wait%(", "")
    if waitCount > 5 then
        score = score - 10
    end
    
    -- Bonus por cachear servicios
    if code:find("local .* = game:GetService") then
        score = score + 5
    end
    
    -- Penalizar string concatenation en loops
    if code:find("for .* do") and code:find('%.%.') then
        score = score - 10
    end
    
    return math.max(0, math.min(100, score))
end

function MetaThink:AnalyzeMaintainability(code: string): number
    local score = 100
    
    -- Complejidad ciclomÃ¡tica
    local complexity = _G.PatternRecognizer:CalculateComplexity(code)
    if complexity > 20 then
        score = score - 20
    elseif complexity > 10 then
        score = score - 10
    end
    
    -- Bonus por usar funciones
    local _, functionCount = code:gsub("function", "")
    score = score + math.min(15, functionCount * 3)
    
    -- Penalizar cÃ³digo muy largo
    if #code > 1000 then
        score = score - 15
    end
    
    return math.max(0, math.min(100, score))
end

function MetaThink:AnalyzeSecurity(code: string): number
    local score = 100
    
    -- Bonus por usar pcall
    if code:find("pcall") then
        score = score + 10
    else
        score = score - 15
    end
    
    -- Penalizar loadstring (riesgo de seguridad)
    if code:find("loadstring") then
        score = score - 30
    end
    
    -- Bonus por validar inputs
    if code:find("if .* then") and code:find("type%(") then
        score = score + 5
    end
    
    -- Penalizar acceso directo a _G sin verificar
    if code:find("_G%.") and not code:find("_G%..- or") then
        score = score - 5
    end
    
    return math.max(0, math.min(100, score))
end

function MetaThink:GenerateSuggestions(analysis: any, code: string): {any}
    local suggestions = {}
    
    if analysis.readability_score < 70 then
        table.insert(suggestions, {
            category = "Legibilidad",
            message = "El cÃ³digo podrÃ­a ser mÃ¡s legible. Considera agregar mÃ¡s comentarios.",
            ai_source = "Claude"
        })
    end
    
    if analysis.performance_score < 70 then
        table.insert(suggestions, {
            category = "Rendimiento",
            message = "Hay oportunidades de optimizaciÃ³n. Revisa loops y cachea referencias.",
            ai_source = "DeepSeek"
        })
    end
    
    if analysis.security_score < 70 then
        table.insert(suggestions, {
            category = "Seguridad",
            message = "Agrega mÃ¡s validaciÃ³n y usa pcall() para operaciones riesgosas.",
            ai_source = "ChatGPT"
        })
    end
    
    if analysis.maintainability_score < 70 then
        table.insert(suggestions, {
            category = "Mantenibilidad",
            message = "El cÃ³digo es complejo. Considera dividirlo en funciones mÃ¡s pequeÃ±as.",
            ai_source = "Claude"
        })
    end
    
    return suggestions
end

function MetaThink:GenerateMetaReport(): {any}
    local avgQuality = 0
    for _, analysis in ipairs(self.code_analyses) do
        avgQuality = avgQuality + analysis.quality_score
    end
    
    if #self.code_analyses > 0 then
        avgQuality = avgQuality / #self.code_analyses
    end
    
    return {
        total_analyses = #self.code_analyses,
        avg_quality = string.format("%.1f", avgQuality),
        recent_analyses = self:GetRecentAnalyses(5)
    }
end

function MetaThink:GetRecentAnalyses(count: number): {any}
    local recent = {}
    local startIdx = math.max(1, #self.code_analyses - count + 1)
    
    for i = startIdx, #self.code_analyses do
        table.insert(recent, self.code_analyses[i])
    end
    
    return recent
end

_G.MetaThink = MetaThink.new()
print("âœ… [3/5] Meta-Think System (Claude) - ACTIVE")

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ¯ SISTEMA 4: CONTEXT UNDERSTANDING (ChatGPT)
-- Entiende comandos complejos y contexto del usuario
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

local ContextUnderstanding = {}
ContextUnderstanding.__index = ContextUnderstanding

function ContextUnderstanding.new()
    local self = setmetatable({}, ContextUnderstanding)
    
    self.conversation_history = {}
    self.user_preferences = {
        preferred_style = "modern",
        typical_requests = {},
        platform = "unknown"
    }
    
    self.abbreviations = {
        -- UI/Visual
        ui = "interfaz",
        menu = "menu",
        hud = "heads up display",
        npc = "non player character",
        fx = "efectos",
        vfx = "efectos visuales",
        sfx = "efectos de sonido",
        
        -- Movement
        tp = "teleport",
        tele = "teleport",
        ws = "walkspeed",
        jp = "jumppower",
        
        -- Technical
        fps = "frames per segundo",
        ms = "milisegundos",
        kb = "kilobytes",
        mb = "megabytes",
        api = "application programming interface",
        
        -- Game
        dmg = "damage",
        hp = "health points",
        mp = "mana points",
        xp = "experience points",
        lvl = "level",
        
        -- Common
        pls = "please",
        plz = "please",
        thx = "thanks",
        ty = "thank you"
    }
    
    return self
end

function ContextUnderstanding:AnalyzeIntent(userInput: string): {any}
    local intent = {
        primary_action = "unknown",
        secondary_actions = {},
        parameters = {},
        entities = {},
        sentiment = "neutral",
        confidence = 0,
        expanded_input = self:ExpandAbbreviations(userInput)
    }
    
    local lower = userInput:lower()
    
    -- Detectar acciÃ³n principal
    if lower:find("crea") or lower:find("crear") or lower:find("haz") or lower:find("hacer") then
        intent.primary_action = "create"
        intent.confidence = intent.confidence + 25
    elseif lower:find("muestra") or lower:find("mostrar") or lower:find("ver") then
        intent.primary_action = "show"
        intent.confidence = intent.confidence + 25
    elseif lower:find("modifica") or lower:find("cambia") or lower:find("edita") then
        intent.primary_action = "modify"
        intent.confidence = intent.confidence + 25
    elseif lower:find("elimina") or lower:find("borra") or lower:find("quita") then
        intent.primary_action = "delete"
        intent.confidence = intent.confidence + 25
    elseif lower:find("activa") or lower:find("enciende") or lower:find("on") then
        intent.primary_action = "enable"
        intent.confidence = intent.confidence + 20
    elseif lower:find("desactiva") or lower:find("apaga") or lower:find("off") then
        intent.primary_action = "disable"
        intent.confidence = intent.confidence + 20
    end
    
    -- Detectar parÃ¡metros
    intent.parameters = self:ExtractParameters(userInput)
    
    -- Detectar entidades (objetos target)
    intent.entities = self:ExtractEntities(userInput)
    
    -- Analizar sentimiento
    intent.sentiment = self:AnalyzeSentiment(userInput)
    
    -- Ajustar confianza segÃºn parÃ¡metros
    if #intent.parameters > 0 then
        intent.confidence = intent.confidence + 15
    end
    if #intent.entities > 0 then
        intent.confidence = intent.confidence + 15
    end
    
    intent.confidence = math.min(100, intent.confidence)
    
    table.insert(self.conversation_history, {
        input = userInput,
        intent = intent,
        timestamp = tick()
    })
    
    return intent
end

function ContextUnderstanding:ExtractParameters(input: string): {any}
    local params = {}
    
    -- Extraer nÃºmeros
    for num in input:gmatch("%d+") do
        table.insert(params, {
            type = "number",
            value = tonumber(num)
        })
    end
    
    -- Extraer coordenadas (x=, y=, z=)
    local x = input:match("x%s*=%s*([%d%-]+)")
    local y = input:match("y%s*=%s*([%d%-]+)")
    local z = input:match("z%s*=%s*([%d%-]+)")
    
    if x and y and z then
        table.insert(params, {
            type = "coordinates",
            value = {x = tonumber(x), y = tonumber(y), z = tonumber(z)}
        })
    end
    
    -- Extraer colores
    if input:lower():find("rojo") or input:lower():find("red") then
        table.insert(params, {type = "color", value = "red"})
    elseif input:lower():find("azul") or input:lower():find("blue") then
        table.insert(params, {type = "color", value = "blue"})
    elseif input:lower():find("verde") or input:lower():find("green") then
        table.insert(params, {type = "color", value = "green"})
    end
    
    -- Extraer calidad/estilo
    if input:lower():find("profesional") or input:lower():find("pro") then
        table.insert(params, {type = "quality", value = "professional"})
    elseif input:lower():find("simple") or input:lower():find("bÃ¡sico") then
        table.insert(params, {type = "quality", value = "simple"})
    elseif input:lower():find("avanzado") or input:lower():find("completo") then
        table.insert(params, {type = "quality", value = "advanced"})
    end
    
    return params
end

function ContextUnderstanding:ExtractEntities(input: string): {any}
    local entities = {}
    local lower = input:lower()
    
    -- UI Elements
    if lower:find("menu") or lower:find("panel") then
        table.insert(entities, {type = "ui", value = "menu"})
    end
    if lower:find("boton") or lower:find("button") then
        table.insert(entities, {type = "ui", value = "button"})
    end
    if lower:find("notificaci") then
        table.insert(entities, {type = "ui", value = "notification"})
    end
    
    -- Visual Effects
    if lower:find("particula") or lower:find("particle") then
        table.insert(entities, {type = "vfx", value = "particles"})
    end
    if lower:find("luz") or lower:find("light") then
        table.insert(entities, {type = "vfx", value = "light"})
    end
    
    -- Movement
    if lower:find("velocidad") or lower:find("speed") then
        table.insert(entities, {type = "movement", value = "speed"})
    end
    if lower:find("salto") or lower:find("jump") then
        table.insert(entities, {type = "movement", value = "jump"})
    end
    
    return entities
end

function ContextUnderstanding:AnalyzeSentiment(input: string): string
    local lower = input:lower()
    
    -- Positivo
    if lower:find("genial") or lower:find("perfecto") or lower:find("gracias") or 
       lower:find("excelente") or lower:find("increible") then
        return "positive"
    end
    
    -- Negativo
    if lower:find("no funciona") or lower:find("error") or lower:find("mal") or
       lower:find("ayuda") or lower:find("problema") then
        return "negative"
    end
    
    -- Urgente
    if lower:find("urgente") or lower:find("rapido") or lower:find("ahora") or
       lower:find("ya") then
        return "urgent"
    end
    
    return "neutral"
end

function ContextUnderstanding:ExpandAbbreviations(input: string): string
    local expanded = input
    
    for abbr, full in pairs(self.abbreviations) do
        -- Reemplazar abreviaciones (word boundary aware)
        expanded = expanded:gsub("%f[%w]" .. abbr .. "%f[%W]", full)
    end
    
    return expanded
end

function ContextUnderstanding:RememberPreference(key: string, value: any)
    self.user_preferences[key] = value
end

function ContextUnderstanding:GetContext(): {any}
    return {
        conversation_length = #self.conversation_history,
        user_preferences = self.user_preferences,
        recent_intents = self:GetRecentIntents(3)
    }
end

function ContextUnderstanding:GetRecentIntents(count: number): {any}
    local recent = {}
    local startIdx = math.max(1, #self.conversation_history - count + 1)
    
    for i = startIdx, #self.conversation_history do
        table.insert(recent, self.conversation_history[i].intent)
    end
    
    return recent
end

_G.ContextUnderstanding = ContextUnderstanding.new()
print("âœ… [4/5] Context Understanding System (ChatGPT) - ACTIVE")

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ’¡ SISTEMA 5: PREDICTIVE SUGGESTIONS (Gemini)
-- Sugiere prÃ³ximos comandos basado en patrones
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

local PredictiveSuggestions = {}
PredictiveSuggestions.__index = PredictiveSuggestions

function PredictiveSuggestions.new()
    local self = setmetatable({}, PredictiveSuggestions)
    
    self.command_sequences = {}
    self.usage_patterns = {}
    self.time_patterns = {}
    self.complementary_commands = {
        crear_menu = {"notificaciones", "barra_stats", "adaptar_ui"},
        particulas = {"iluminacion", "camera_shake"},
        velocidad = {"salto", "volar"},
        template_tycoon = {"sistema_economico", "sistema_slots"},
        auto_farm = {"esp", "fullbright"}
    }
    
    return self
end

function PredictiveSuggestions:RecordCommand(command: string, success: boolean)
    -- Actualizar patrones de uso
    self.usage_patterns[command] = self.usage_patterns[command] or {
        total_uses = 0,
        success_count = 0,
        last_used = 0
    }
    
    self.usage_patterns[command].total_uses = self.usage_patterns[command].total_uses + 1
    self.usage_patterns[command].last_used = tick()
    
    if success then
        self.usage_patterns[command].success_count = 
            self.usage_patterns[command].success_count + 1
    end
    
    -- Detectar secuencias
    if _G.TycoonAI.Stats.LastCommand then
        local sequence = _G.TycoonAI.Stats.LastCommand .. " -> " .. command
        self.command_sequences[sequence] = (self.command_sequences[sequence] or 0) + 1
    end
    
    -- Registrar hora del dÃ­a
    local hour = tonumber(os.date("%H"))
    self.time_patterns[command] = self.time_patterns[command] or {}
    self.time_patterns[command][hour] = (self.time_patterns[command][hour] or 0) + 1
end

function PredictiveSuggestions:SuggestNext(lastCommand: string, count: number): {any}
    local suggestions = {}
    
    count = count or 3
    
    -- 1. Sugerencias complementarias
    if self.complementary_commands[lastCommand] then
        for _, cmd in ipairs(self.complementary_commands[lastCommand]) do
            table.insert(suggestions, {
                command = cmd,
                reason = "Complementa bien con " .. lastCommand,
                confidence = 85,
                ai_source = "Gemini"
            })
        end
    end
    
    -- 2. Sugerencias por secuencia
    for sequence, count in pairs(self.command_sequences) do
        if sequence:find("^" .. lastCommand .. " %-%>") then
            local nextCmd = sequence:match("%-> (.+)$")
            if nextCmd then
                table.insert(suggestions, {
                    command = nextCmd,
                    reason = "Sueles usarlo despuÃ©s de " .. lastCommand,
                    confidence = math.min(95, 50 + count * 5),
                    ai_source = "Pattern Analysis"
                })
            end
        end
    end
    
    -- 3. Comandos mÃ¡s exitosos
    local successfulCommands = {}
    for cmd, pattern in pairs(self.usage_patterns) do
        if pattern.total_uses > 0 then
            local successRate = pattern.success_count / pattern.total_uses
            if successRate > 0.8 then
                table.insert(successfulCommands, {
                    command = cmd,
                    success_rate = successRate,
                    uses = pattern.total_uses
                })
            end
        end
    end
    
    table.sort(successfulCommands, function(a, b)
        return a.success_rate > b.success_rate
    end)
    
    for i = 1, math.min(2, #successfulCommands) do
        local cmd = successfulCommands[i]
        table.insert(suggestions, {
            command = cmd.command,
            reason = "Comando confiable (" .. math.floor(cmd.success_rate * 100) .. "% Ã©xito)",
            confidence = math.floor(cmd.success_rate * 100),
            ai_source = "Success Metrics"
        })
    end
    
    -- Ordenar por confianza y limitar
    table.sort(suggestions, function(a, b)
        return a.confidence > b.confidence
    end)
    
    local result = {}
    for i = 1, math.min(count, #suggestions) do
        table.insert(result, suggestions[i])
    end
    
    return result
end

function PredictiveSuggestions:GenerateSmartSuggestions(context: {any}): {any}
    local suggestions = {
        next_commands = {},
        contextual = {},
        learning_based = {}
    }
    
    -- Sugerencias basadas en Ãºltimo comando
    if context.last_command then
        suggestions.next_commands = self:SuggestNext(context.last_command, 3)
    end
    
    -- Sugerencias contextuales
    if context.context == "ui" then
        table.insert(suggestions.contextual, {
            command = "adaptar_ui",
            reason = "Optimiza UI para tu dispositivo"
        })
    elseif context.context == "movement" then
        table.insert(suggestions.contextual, {
            command = "noclip",
            reason = "Ãštil para exploraciÃ³n"
        })
    end
    
    -- Sugerencias basadas en aprendizaje
    if _G.PatternRecognizer then
        local bestPatterns = _G.PatternRecognizer:GetBestPatterns()
        for i = 1, math.min(3, #bestPatterns) do
            table.insert(suggestions.learning_based, {
                pattern = bestPatterns[i].name,
                success_rate = bestPatterns[i].success_rate,
                reason = "Ha funcionado bien " .. math.floor(bestPatterns[i].success_rate * 100) .. "% de las veces"
            })
        end
    end
    
    return suggestions
end

_G.PredictiveSuggestions = PredictiveSuggestions.new()
print("âœ… [5/5] Predictive Suggestions System (Gemini) - ACTIVE")

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ§  INTEGRACIÃ“N: TYCOON AI BRAIN
-- Sistema que conecta todos los subsistemas
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_G.TycoonAI.Brain = {
    PatternRecognizer = _G.PatternRecognizer,
    HumilityCore = _G.HumilityCore,
    MetaThink = _G.MetaThink,
    ContextUnderstanding = _G.ContextUnderstanding,
    PredictiveSuggestions = _G.PredictiveSuggestions
}

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ”— INTEGRADOR PRINCIPAL - Conecta todos los subsistemas
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_G.TycoonAI.Brain = {
    PatternRecognizer = _G.PatternRecognizer,
    HumilityCore = _G.HumilityCore,
    MetaThink = _G.MetaThink,
    ContextUnderstanding = _G.ContextUnderstanding,
    PredictiveSuggestions = _G.PredictiveSuggestions
}

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ” NUEVA FUNCIÃ“N: BUSCAR Y EJECUTAR COMANDOS EN DATABASE
-- Esta funciÃ³n conecta el Brain con la Database para ejecutar comandos reales
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function _G.TycoonAI.Brain:FindAndExecuteCommand(commandName: string): {any}
    print("   [ğŸ”] Buscando comando: \"" .. commandName .. "\" en Database...")
    
    -- Verificar que la Database estÃ© cargada
    if not _G.TycoonAI.Database then
        warn("   âŒ Database no estÃ¡ cargada")
        return {
            success = false,
            message = "âŒ Database no disponible. AsegÃºrate de cargar Database_Part1 y Part2 primero.",
            command_found = false
        }
    end
    
    -- Lista de categorÃ­as donde buscar
    local categories = {
        "Movement", "UI", "VisualEffects", "Controls", 
        "Utilities", "Economy", "Templates", "System",
        "Audio", "Lighting", "Physics", "Network",
        "Storage", "Animation", "Security", "Advanced"
    }
    
    local inputLower = commandName:lower()
    
    -- Buscar en todas las categorÃ­as
    for _, category in ipairs(categories) do
        local categoryData = _G.TycoonAI.Database[category]
        
        if categoryData then
            for _, command in ipairs(categoryData) do
                -- Buscar coincidencias en keywords
                for _, keyword in ipairs(command.keywords) do
                    if inputLower:find(keyword:lower(), 1, true) then
                        print("   âœ… Comando encontrado: \"" .. command.name .. "\" (CategorÃ­a: " .. category .. ")")
                        
                        -- Extraer parÃ¡metros del input (nÃºmeros)
                        local params = {}
                        for number in commandName:gmatch("%d+") do
                            table.insert(params, tonumber(number))
                        end
                        
                        -- Ejecutar el cÃ³digo del comando
                        local success, result = pcall(function()
                            if #params > 0 then
                                return command.code(params[1], params[2], params[3])
                            else
                                return command.code()
                            end
                        end)
                        
                        if success and result then
                            -- Registrar ejecuciÃ³n exitosa
                            _G.TycoonAI.Stats.CommandsExecuted = _G.TycoonAI.Stats.CommandsExecuted + 1
                            _G.TycoonAI.Stats.LastCommand = command.name
                            
                            return {
                                success = true,
                                message = result.message or "âœ… Comando ejecutado: " .. command.name,
                                command_name = command.name,
                                command_found = true,
                                category = category,
                                description = command.description,
                                parameters_used = params
                            }
                        else
                            -- Error al ejecutar
                            _G.TycoonAI.Stats.ErrorsLearned = _G.TycoonAI.Stats.ErrorsLearned + 1
                            
                            return {
                                success = false,
                                message = "âŒ Error ejecutando \"" .. command.name .. "\": " .. tostring(result),
                                command_found = true,
                                command_name = command.name,
                                error_details = tostring(result)
                            }
                        end
                    end
                end
            end
        end
    end
    
    -- No se encontrÃ³ el comando
    print("   âš ï¸ No se encontrÃ³ comando que coincida con: \"" .. commandName .. "\"")
    
    return {
        success = false,
        message = "âŒ No encontrÃ© un comando que coincida con: \"" .. commandName .. "\"\nğŸ’¡ Intenta con: velocidad, salto, menu, particulas, etc.",
        command_found = false,
        suggestions_needed = true
    }
end

function _G.TycoonAI.Brain:ProcessIntelligently(userInput: string): {any}
    local startTime = tick()
    
    local result = {
        success = false,
        message = "",
        suggestions = {},
        learning = {},
        confidence = 0,
        ai_insights = {},
        execution_time = 0
    }
    
    print("\nğŸ§  [BRAIN] Procesando input: \"" .. userInput .. "\"")
    
    -- 1. Entender contexto (ChatGPT)
    print("   [1/6] ChatGPT analizando contexto...")
    local intent = self.ContextUnderstanding:AnalyzeIntent(userInput)
    local expanded = self.ContextUnderstanding:ExpandAbbreviations(userInput)
    
    result.confidence = intent.confidence
    result.ai_insights["ChatGPT"] = {
        primary_action = intent.primary_action,
        sentiment = intent.sentiment,
        parameters_found = #intent.parameters
    }
    
    print("      âœ… AcciÃ³n detectada: " .. intent.primary_action)
    print("      âœ… Confianza: " .. intent.confidence .. "%")
    
    -- 2. ğŸ†• BUSCAR Y EJECUTAR COMANDO EN DATABASE
    print("   [2/6] ğŸ” Buscando comando en Database...")
    local commandResult = self:FindAndExecuteCommand(userInput)
    
    if commandResult.command_found then
        result.success = commandResult.success
        result.message = commandResult.message
        result.command_executed = commandResult.command_name
        result.category = commandResult.category
        
        print("      " .. (commandResult.success and "âœ…" or "âŒ") .. " " .. commandResult.message)
    else
        result.message = commandResult.message
        print("      âš ï¸ Comando no encontrado en Database")
    end
    
    -- 3. Expresar incertidumbre si es baja (DeepSeek)
    print("   [3/6] DeepSeek evaluando confianza...")
    local commandName = commandResult.command_name or intent.primary_action
    local humilityConfidence = self.HumilityCore:CalculateConfidence(commandName, intent.parameters)
    
    if humilityConfidence < 70 then
        result.ai_insights["DeepSeek"] = {
            confidence = humilityConfidence,
            humility_response = "Tengo " .. humilityConfidence .. "% de confianza. Procedo con precauciÃ³n."
        }
        print("      âš ï¸ Confianza baja: " .. humilityConfidence .. "%")
    else
        result.ai_insights["DeepSeek"] = {
            confidence = humilityConfidence,
            humility_response = "Confianza aceptable"
        }
        print("      âœ… Confianza aceptable: " .. humilityConfidence .. "%")
    end
    
    -- 4. Generar sugerencias predictivas (Gemini)
    print("   [4/6] Gemini generando sugerencias...")
    local predictions = self.PredictiveSuggestions:GenerateSmartSuggestions({
        last_command = _G.TycoonAI.Stats.LastCommand,
        context = intent.entities[1] and intent.entities[1].type or "general"
    })
    
    result.suggestions = predictions.next_commands
    result.ai_insights["Gemini"] = {
        suggestions_generated = #predictions.next_commands,
        best_suggestion = predictions.next_commands[1] and predictions.next_commands[1].command or "none"
    }
    
    print("      âœ… " .. #predictions.next_commands .. " sugerencias generadas")
    
    -- 5. Si se ejecutÃ³ cÃ³digo, analizarlo (Claude)
    if result.command_executed then
        print("   [5/6] Claude analizando ejecuciÃ³n...")
        result.learning.command_quality = commandResult.success and 100 or 50
        
        result.ai_insights["Claude"] = {
            quality_score = result.learning.command_quality,
            analysis = "Command executed from Database",
            command_category = commandResult.category
        }
        
        print("      âœ… Calidad de ejecuciÃ³n: " .. result.learning.command_quality .. "/100")
        
        -- 6. Analizar patrones (DeepSeek)
        print("   [6/6] DeepSeek aprendiendo patrones...")
        if commandResult.success then
            -- Registrar patrÃ³n exitoso
            self.HumilityCore:LearnFromOutcome(commandName, true, "Command executed successfully")
            
            -- Actualizar predicciones
            self.PredictiveSuggestions:LogCommandUsage(commandName, true)
        end
        
        print("      âœ… PatrÃ³n registrado en base de conocimiento")
    end
    
    result.execution_time = tick() - startTime
    
    print("   â±ï¸ Tiempo total: " .. string.format("%.3f", result.execution_time) .. "s")
    print("   âœ… Procesamiento inteligente completado")
    print("   " .. (result.success and "ğŸ‰ Comando ejecutado exitosamente!" or "âš ï¸ No se pudo ejecutar el comando") .. "\n")
    
    return result
end

function _G.TycoonAI.Brain:GetIntelligenceReport(): {any}
    local report = {
        version = _G.TycoonAI.Version,
        timestamp = os.date("%Y-%m-%d %H:%M:%S"),
        uptime = string.format("%.1f", (tick() - _G.TycoonAI.Stats.StartTime) / 60) .. " minutes",
        
        -- EstadÃ­sticas generales
        stats = _G.TycoonAI.Stats,
        
        -- Pattern Recognition (DeepSeek)
        patterns = self.PatternRecognizer:GenerateReport(),
        
        -- Humility Core (DeepSeek)
        humility = self.HumilityCore:GenerateHumilityReport(),
        
        -- Meta-Think (Claude)
        meta_analysis = self.MetaThink:GenerateMetaReport(),
        
        -- Context Understanding (ChatGPT)
        context = self.ContextUnderstanding:GetContext(),
        
        -- AI Collaboration
        collaboration = {
            active_ais = #_G.TycoonAI.Contributors,
            contributors = _G.TycoonAI.Contributors,
            message = "5 AIs working as ONE"
        }
    }
    
    return report
end

function _G.TycoonAI.Brain:PrintReport()
    print("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("    ğŸ§  TYCOON AI BRAIN - INTELLIGENCE REPORT")
    print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    local report = self:GetIntelligenceReport()
    
    print("\nğŸ“Š ESTADÃSTICAS GENERALES:")
    print("   Comandos ejecutados: " .. report.stats.CommandsExecuted)
    print("   Tasa de Ã©xito: " .. report.stats.SuccessRate .. "%")
    print("   Errores aprendidos: " .. report.stats.ErrorsLearned)
    print("   Patrones descubiertos: " .. report.stats.PatternsDiscovered)
    print("   Tiempo activo: " .. report.uptime)
    
    print("\nğŸ” PATTERN RECOGNITION (DeepSeek):")
    print("   Patrones analizados: " .. report.patterns.total_patterns_analyzed)
    print("   Complejidad promedio: " .. report.patterns.avg_complexity)
    print("   Mejores patrones: " .. #report.patterns.best_patterns)
    
    print("\nğŸ’­ HUMILITY CORE (DeepSeek):")
    local lessons = report.humility.lessons_learned
    print("   Lecciones aprendidas: " .. lessons.total_lessons)
    print("   Ã‰xitos: " .. lessons.successes)
    print("   Errores: " .. lessons.errors)
    print("   Tasa de Ã©xito: " .. string.format("%.1f", lessons.success_rate) .. "%")
    
    print("\nğŸ¤” META-THINK (Claude):")
    print("   AnÃ¡lisis realizados: " .. report.meta_analysis.total_analyses)
    print("   Calidad promedio: " .. report.meta_analysis.avg_quality .. "/100")
    
    print("\nğŸ¯ CONTEXT UNDERSTANDING (ChatGPT):")
    print("   Conversaciones: " .. report.context.conversation_length)
    print("   Preferencias guardadas: " .. (report.context.user_preferences and "SÃ­" or "No"))
    
    print("\nğŸ¤ COLABORACIÃ“N DE IAs:")
    print("   IAs activas: " .. report.collaboration.active_ais)
    for _, ai in ipairs(report.collaboration.contributors) do
        print("      âœ… " .. ai)
    end
    
    print("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("    " .. report.collaboration.message)
    print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
end

print("\nğŸ‰ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
print("    TYCOON AI BRAIN v17.1.1 FIXED - FULLY OPERATIONAL")
print("    All 5 AI systems integrated and working together")
print("    ğŸ”§ Con integraciÃ³n completa a Database!")
print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

-- Ejemplo de uso
print("ğŸ“ EJEMPLO DE USO:")
print("   _G.TycoonAI.Brain:ProcessIntelligently('velocidad 100')")
print("   _G.TycoonAI.Brain:FindAndExecuteCommand('salto')")
print("   _G.TycoonAI.Brain:GetIntelligenceReport()")
print("   _G.TycoonAI.Brain:PrintReport()")

print("\nğŸ’™ Ready to create amazing experiences together!")
print("   'No solo generamos cÃ³digo. Creamos experiencias. Construimos sueÃ±os.'\n")

return _G.TycoonAI.Brain
